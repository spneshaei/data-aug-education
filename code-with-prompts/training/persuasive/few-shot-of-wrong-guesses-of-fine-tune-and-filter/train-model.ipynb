{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentence_only_with_folds_df = pd.read_csv(\"ANON\")\n",
    "fine_tune_df = pd.read_csv(f\"ANON\")\n",
    "few_shot_of_wrong_guesses_of_fine_tune_df = pd.read_csv(f\"ANON\")\n",
    "few_shot_of_wrong_guesses_of_fine_tune_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_and_relabel_outputs = pd.read_csv(f\"ANON\")\n",
    "filter_and_relabel_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows in filter_and_relabel_outputs that new_label and original_label are different\n",
    "diff_df = filter_and_relabel_outputs[filter_and_relabel_outputs[\"new_label\"] != filter_and_relabel_outputs[\"original_label\"]]\n",
    "print(len(fine_tune_df))\n",
    "print(len(diff_df))\n",
    "fine_tune_df = fine_tune_df[~fine_tune_df.text.isin(diff_df.text)]\n",
    "print(len(fine_tune_df))\n",
    "diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_and_relabel_outputs_wrong_preds = pd.read_csv(f\"ANON\")\n",
    "filter_and_relabel_outputs_wrong_preds.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows in filter_and_relabel_outputs_wrong_preds that new_label and original_label are different\n",
    "diff_df_wrong_preds = filter_and_relabel_outputs_wrong_preds[filter_and_relabel_outputs_wrong_preds[\"new_label\"] != filter_and_relabel_outputs_wrong_preds[\"original_label\"]]\n",
    "print(len(few_shot_of_wrong_guesses_of_fine_tune_df))\n",
    "print(len(diff_df_wrong_preds))\n",
    "few_shot_of_wrong_guesses_of_fine_tune_df = few_shot_of_wrong_guesses_of_fine_tune_df[~few_shot_of_wrong_guesses_of_fine_tune_df.text.isin(diff_df_wrong_preds.text)]\n",
    "print(len(few_shot_of_wrong_guesses_of_fine_tune_df))\n",
    "diff_df_wrong_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sentence_only_with_folds_df))\n",
    "train_df = sentence_only_with_folds_df[sentence_only_with_folds_df.test_fold != fold]\n",
    "# remove columns text-id, id, test_fold\n",
    "train_df = train_df.drop(columns=['id', 'test_fold'])\n",
    "print(len(train_df))\n",
    "\n",
    "print(len(fine_tune_df))\n",
    "train_df_2 = fine_tune_df[fine_tune_df.test_fold != fold]\n",
    "# remove columns text-id, id, test_fold, original_id, test_fold\n",
    "train_df_2 = train_df_2.drop(columns=['id', 'test_fold', 'original_id', 'test_fold'])\n",
    "print(len(train_df_2))\n",
    "\n",
    "train_df_3 = few_shot_of_wrong_guesses_of_fine_tune_df.drop(columns=['id', 'original_id'])\n",
    "\n",
    "train_df = pd.concat([train_df, train_df_2, train_df_3])\n",
    "\n",
    "print(len(train_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle train_df with seed 42\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "model = ClassificationModel('bert', 'bert-base-german-cased', num_labels=max(train_df.label) + 1, use_cuda=False, args={'output_dir': f'output-fold-{fold}', 'num_train_epochs': 3})\n",
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sentence_only_with_folds_df[sentence_only_with_folds_df.test_fold == fold]\n",
    "\n",
    "# find F1 score per label\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def f1_score_per_label(y_true, y_pred):\n",
    "    return np.array([f1_score(y_true == i, y_pred == i) for i in range(max(y_true) + 1)])\n",
    "\n",
    "predictions, raw_outputs = model.predict(test_df.text.to_list())\n",
    "list_of_f1 = list(f1_score_per_label(test_df.label, predictions))\n",
    "\n",
    "overall_f1 = f1_score(test_df.label, predictions, average='weighted')\n",
    "overall_balanced_accuracy = balanced_accuracy_score(test_df.label, predictions)\n",
    "with open(f'f1-fold-{fold}.txt', 'w') as f:\n",
    "    for item in list_of_f1 + [overall_f1, overall_balanced_accuracy]:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the texts that the model got wrong, print 5 of them with the correct and predicted labels\n",
    "predictions_train, raw_outputs_train = model.predict(train_df.text.to_list())\n",
    "wrong_df = train_df[train_df.label != predictions_train]\n",
    "wrong_df.to_csv(f'wrong-predictions-fold-{fold}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
