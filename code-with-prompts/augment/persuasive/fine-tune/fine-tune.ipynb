{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the fine-tuning file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "main_df = pd.read_csv(\"../../../input-data-all-together/discourse/sentence-only-with-folds.csv\")\n",
    "# only get the rows with test_fold != fold\n",
    "df = main_df[main_df.test_fold != fold]\n",
    "\n",
    "df.head() # columns: text-id, text, label, id, test_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the rows with 42\n",
    "df = df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\n",
    "    0: \"Evidence\",\n",
    "    1: \"Claim\",\n",
    "    2: \"Concluding Statement\",\n",
    "    3: \"Lead\",\n",
    "    4: \"Position\",\n",
    "    5: \"Counterclaim\",\n",
    "    6: \"Rebuttal\"\n",
    "}\n",
    "\n",
    "developer_prompt = \"You are an expert in analyzing persuasive essays and understanding argumentative and discourse elements. The discourse elements are: Lead, Position, Claim, Counterclaim, Rebuttal, Evidence, and Concluding Statement. Lead refers to an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader's attention and point toward the thesis. Position refers to an opinion or conclusion on the main question. Claim refers to a claim that supports the position. Counterclaim refers to a claim that refutes another claim or gives an opposing reason to the position. Rebuttal refers to a claim that refutes a counterclaim. Evidence refers to ideas or examples that support claims, counterclaims, rebuttals, or the position. Concluding statement refers to a concluding statement that restates the position and claims.\"\n",
    "\n",
    "final_jsonl_data = []\n",
    "for index, row in df.iterrows():\n",
    "    final_jsonl_data.append({\"messages\": [{\"role\": \"system\", \"content\": developer_prompt}, {\"role\": \"user\", \"content\": \"Please output a sentence that belongs to the \" + MAPPING[row[\"label\"]] + \" discourse element. Just output the sentence and nothing else.\"}, {\"role\": \"assistant\", \"content\": row[\"text\"]}]})\n",
    "\n",
    "import jsonl\n",
    "jsonl.dump(final_jsonl_data, f\"jsonl-gpt-fold-{fold}.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data with the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find label count distribution and store it as a dict\n",
    "label_count = df['label'].value_counts().to_dict()\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum label count\n",
    "max_label_count = max(label_count.values())\n",
    "\n",
    "# Calculate the difference needed for each class to reach the maximum count\n",
    "label_count_diff = {label: max_label_count - count for label, count in label_count.items()}\n",
    "\n",
    "label_count_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many augmentations should we do per sentence, by dividing the count diff by the number of sentences already in that class\n",
    "augmentation_count_needed = {label: diff // count for label, diff, count in zip(label_count.keys(), label_count_diff.values(), label_count.values())}\n",
    "augmentation_count_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import backoff\n",
    "\n",
    "with open(\"../../../api_key.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "openai.api_key = api_key\n",
    "openai_client = OpenAI(api_key=api_key)\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.OpenAIError, max_time=120)\n",
    "def return_sentence_from_openai(class_name, temperature = 0.5):\n",
    "    global openai_client\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"ANON\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": developer_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"Please output a sentence that belongs to the \" + class_name + \" discourse element. Just output the sentence and nothing else.\"}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "sentences = [] # {index: XX, text: XX, label: XX}\n",
    "\n",
    "with tqdm(total=len(df)) as pbar:\n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(augmentation_count_needed[row[\"label\"]]):\n",
    "            mapping_label_text = MAPPING[row[\"label\"]]\n",
    "            sentence = return_sentence_from_openai(mapping_label_text)\n",
    "            sentences.append({\"index\": index, \"text\": sentence, \"label\": row[\"label\"]})\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe id,text-id,text,label,original_id,test_fold, by using the df we had in the beginning\n",
    "result_df = pd.DataFrame(columns=[\"id\", \"text-id\", \"text\", \"label\", \"original_id\", \"test_fold\"])\n",
    "\n",
    "index_of_sentence = 0\n",
    "with tqdm(total=len(df)) as pbar:\n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(augmentation_count_needed[row[\"label\"]]):\n",
    "            sentence = sentences[index_of_sentence][\"text\"]\n",
    "            new_row = {\n",
    "                \"id\": f\"augmented-{row['id']}-{i}\",\n",
    "                \"text-id\": row[\"text-id\"],\n",
    "                \"text\": sentence,\n",
    "                \"label\": row[\"label\"],\n",
    "                \"original_id\": row[\"id\"],\n",
    "                \"test_fold\": row[\"test_fold\"]\n",
    "            }\n",
    "            result_df = pd.concat([result_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            index_of_sentence += 1\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f\"fine-tune-fold-{fold}-outputs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
