{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"../../../training/discourse/chain-of-thought/wrong-predictions-fold-{fold}.csv\")\n",
    "\n",
    "df.head() # columns: text, label, id, test_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entries = pd.read_csv(\"../../../input-data-all-together/discourse/sentence-only-with-folds.csv\") \n",
    "all_entries = all_entries[all_entries[\"test_fold\"] != fold]\n",
    "# remove text-id column\n",
    "all_entries = all_entries.drop(columns=[\"text-id\"])\n",
    "all_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def rank_corpus_by_similarity(corpus, target_sentence):\n",
    "    embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "    target_embedding = model.encode(target_sentence, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(target_embedding, embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    top_5_similar = torch.topk(cos_scores, k=5, largest=True)\n",
    "    bottom_5_similar = torch.topk(cos_scores, k=5, largest=False)\n",
    "    \n",
    "    top_5_indices = top_5_similar.indices.numpy()\n",
    "    bottom_5_indices = bottom_5_similar.indices.numpy()\n",
    "    \n",
    "    top_5_sentences = [corpus[i] for i in top_5_indices]\n",
    "    bottom_5_sentences = [corpus[i] for i in bottom_5_indices]\n",
    "    \n",
    "    return top_5_sentences, bottom_5_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\n",
    "    0: \"Evidence\",\n",
    "    1: \"Claim\",\n",
    "    2: \"Concluding Statement\",\n",
    "    3: \"Lead\",\n",
    "    4: \"Position\",\n",
    "    5: \"Counterclaim\",\n",
    "    6: \"Rebuttal\"\n",
    "}\n",
    "\n",
    "developer_prompt = \"You are an expert in analyzing persuasive essays and understanding argumentative and discourse elements. The discourse elements are: Lead, Position, Claim, Counterclaim, Rebuttal, Evidence, and Concluding Statement. Lead refers to an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader's attention and point toward the thesis. Position refers to an opinion or conclusion on the main question. Claim refers to a claim that supports the position. Counterclaim refers to a claim that refutes another claim or gives an opposing reason to the position. Rebuttal refers to a claim that refutes a counterclaim. Evidence refers to ideas or examples that support claims, counterclaims, rebuttals, or the position. Concluding statement refers to a concluding statement that restates the position and claims.\"\n",
    "user_prompts = [] # {id: XX, prompt: YY}\n",
    "\n",
    "# random seed\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "id = 0\n",
    "for index, row in df.iterrows():\n",
    "    top_5_similar, bottom_5_similar = rank_corpus_by_similarity(all_entries[all_entries[\"label\"] == row[\"label\"]][\"text\"].tolist(), row[\"text\"])\n",
    "    sentences_to_use = [\n",
    "        top_5_similar[0],\n",
    "        top_5_similar[1],\n",
    "        bottom_5_similar[-1],\n",
    "        bottom_5_similar[-2],\n",
    "        row[\"text\"]\n",
    "    ]\n",
    "\n",
    "    for sentence_to_use in sentences_to_use:\n",
    "        prompt = \"This sentence is from the \" + MAPPING[row[\"label\"]] + \" discourse element:\\n\" + sentence_to_use + \"\\n\\nFirst, think step by step on why this is a sentence of the \" + MAPPING[row[\"label\"]] + \" discourse element. Then, think step by step, and finally in the last line of your response (after putting a line break), please write a sentence that addresses the same topic, focusing on the \" + MAPPING[row[\"label\"]] + \" discourse element. You should use different names, words, and terminologies in your output, but the overall meaning and content should be the same and refer to the same discourse element. In the *last line* of your output, just put the sentence and nothing else.\"\n",
    "        user_prompts.append({\"id\": id, \"prompt\": prompt})\n",
    "        id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompts[1][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "with open(\"../../../api_key.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "openai.api_key = api_key\n",
    "openai_client = OpenAI(api_key=api_key)\n",
    "\n",
    "def return_message_from_openai(messages, temperature = 1):\n",
    "    global openai_client\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jsonl_data = []\n",
    "\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    jsonl_data.append({\n",
    "        \"custom_id\": f\"request-{i+1}-id-{prompt['id']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-2024-08-06\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt[\"prompt\"]}\n",
    "            ],\n",
    "            \"temperature\": 1.0\n",
    "        }\n",
    "    })\n",
    "\n",
    "with open(f\"cot-of-wrong-guesses-dissimilarity-of-cot-fold-{fold}.jsonl\", \"w\") as f:\n",
    "    for entry in jsonl_data:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file = openai_client.files.create(\n",
    "    file=open(f\"cot-of-wrong-guesses-dissimilarity-of-cot-fold-{fold}.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "created_batch = openai_client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f\"CoT of Wrong Guesses of CoT (fold {fold}) Discourse\"\n",
    "    }\n",
    ")\n",
    "created_batch.id, created_batch.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = openai_client.batches.retrieve(created_batch.id)\n",
    "batch.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = openai_client.files.content(batch.output_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe id,text-id,text,label,original_id,test_fold, by using the df we had in the beginning\n",
    "result_df = pd.DataFrame(columns=[\"id\", \"text\", \"label\", \"original_id\"])\n",
    "\n",
    "lines = file_response.text.split(\"\\n\")\n",
    "id = 0\n",
    "for index, row in df.iterrows():\n",
    "    for j in range(5):\n",
    "        data = json.loads(lines[id])\n",
    "        new_row = {\n",
    "            \"id\": data[\"custom_id\"],\n",
    "            # \"text-id\": df[df[\"id\"] == int(data[\"custom_id\"].split(\"-\")[-1])][\"text-id\"].values[0],\n",
    "            \"text\": data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"],\n",
    "            \"label\": row[\"label\"],\n",
    "            \"original_id\": id\n",
    "            # \"test_fold\": df[df[\"id\"] == int(data[\"custom_id\"].split(\"-\")[-1])][\"test_fold\"].values[0]\n",
    "        }\n",
    "        result_df = pd.concat([result_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        id += 1\n",
    "\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f\"cot-of-wrong-guesses-dissimilarity-of-cot-fold-{fold}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
