{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"ANON\")\n",
    "\n",
    "df.head() # columns: text, label, id, test_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entries = pd.read_csv(\"ANON\") \n",
    "all_entries = all_entries[all_entries[\"test_fold\"] != fold]\n",
    "all_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def rank_corpus_by_similarity(corpus, target_sentence):\n",
    "    embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "    target_embedding = model.encode(target_sentence, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(target_embedding, embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    top_5_similar = torch.topk(cos_scores, k=5, largest=True)\n",
    "    bottom_5_similar = torch.topk(cos_scores, k=5, largest=False)\n",
    "    \n",
    "    top_5_indices = top_5_similar.indices.numpy()\n",
    "    bottom_5_indices = bottom_5_similar.indices.numpy()\n",
    "    \n",
    "    top_5_sentences = [corpus[i] for i in top_5_indices]\n",
    "    bottom_5_sentences = [corpus[i] for i in bottom_5_indices]\n",
    "    \n",
    "    return top_5_sentences, bottom_5_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\n",
    "    0: \"Description\",\n",
    "    1: \"Feelings\",\n",
    "    2: \"Evaluation\",\n",
    "    3: \"Analysis\",\n",
    "    4: \"Conclusion\",\n",
    "    5: \"Action Plan\"\n",
    "}\n",
    "\n",
    "developer_prompt = \"You are an expert in the Gibbs reflective cycle. The components of the Gibbs reflective cycle are: Description, Feelings, Evaluation, Analysis, Conclusion, and Action Plan. Description refers describing to the event or experience you are reflecting on. Feelings refers to your emotions during the event or experience. Evaluation refers to your thoughts about the event or experience, providing positive and negative aspects on what happened. Analysis refers to your understanding of the event or experience, providing reasons behind points mentioned in the Evaluation aspect. Conclusion refers to what you learned from the event or experience. Action Plan refers to what you would do differently in the future (next time). Always respond in German.\"\n",
    "user_prompts = [] # {id: XX, prompt: YY}\n",
    "\n",
    "# random seed\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "id = 0\n",
    "for index, row in df.iterrows():\n",
    "    label = row[\"label\"]\n",
    "    \n",
    "    top_5_similar, bottom_5_similar = rank_corpus_by_similarity(all_entries[all_entries[\"label\"] == label][\"text\"].tolist(), row[\"text\"])\n",
    "\n",
    "    for j in range(5):\n",
    "\n",
    "        prompt = \"These three sentences are reflective sentences from the \" + MAPPING[label] + \" component of the Gibbs reflective cycle:\\n\"\n",
    "        prompt += \"- \" + row[\"text\"] + \"\\n\"\n",
    "        five_sentences = pd.DataFrame({\n",
    "            \"text\": [top_5_similar[j], bottom_5_similar[len(bottom_5_similar) - j - 1]]\n",
    "        })\n",
    "        five_sentences = five_sentences.sample(frac=1, random_state=random.randint(0, 10000)).reset_index(drop=True)\n",
    "        for _, sentence in five_sentences.iterrows():\n",
    "            prompt += \"- \" + sentence[\"text\"] + \"\\n\"\n",
    "        prompt += \"\\nPlease write a sentence that reflects on similar events or experiences, focusing on the \" + MAPPING[label] + \" component of the Gibbs reflective cycle. You should use different names, words, and terminologies in your output, but the overall meaning and content should be similar and refer to the same Gibbs component. Only output one sentence and nothing else. Respond in German.\"\n",
    "        user_prompts.append({\"id\": id, \"prompt\": prompt})\n",
    "        id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompts[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "with open(\"../../../api_key.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "openai.api_key = api_key\n",
    "openai_client = OpenAI(api_key=api_key)\n",
    "\n",
    "def return_message_from_openai(messages, temperature = 1):\n",
    "    global openai_client\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jsonl_data = []\n",
    "\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    jsonl_data.append({\n",
    "        \"custom_id\": f\"request-{i+1}-id-{prompt['id']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-2024-08-06\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt[\"prompt\"]}\n",
    "            ],\n",
    "            \"temperature\": 1.0\n",
    "        }\n",
    "    })\n",
    "\n",
    "with open(f\"few-shot-of-wrong-guesses-dissimilarity-of-fine-tune-fold-{fold}.jsonl\", \"w\") as f:\n",
    "    for entry in jsonl_data:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file = openai_client.files.create(\n",
    "    file=open(f\"few-shot-of-wrong-guesses-dissimilarity-of-fine-tune-fold-{fold}.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "openai_client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f\"Few-shot of Wrong Guesses Dissimilarity of Fine-tune (fold {fold})\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = openai_client.batches.retrieve(\"ANON\")\n",
    "batch.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = openai_client.files.content(batch.output_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_to_use = []\n",
    "for index, row in df.iterrows():\n",
    "    label = row[\"label\"]\n",
    "    for j in range(5):\n",
    "        all_labels_to_use.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe id,text-id,text,label,original_id,test_fold, by using the df we had in the beginning\n",
    "result_df = pd.DataFrame(columns=[\"id\", \"text\", \"label\", \"original_id\"])\n",
    "\n",
    "i = 0\n",
    "for line in file_response.text.split(\"\\n\"):\n",
    "    if line:\n",
    "        data = json.loads(line)\n",
    "        new_row = {\n",
    "            \"id\": data[\"custom_id\"],\n",
    "            # \"text-id\": df[df[\"id\"] == int(data[\"custom_id\"].split(\"-\")[-1])][\"text-id\"].values[0],\n",
    "            \"text\": data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"],\n",
    "            \"label\": all_labels_to_use[i],\n",
    "            \"original_id\": int(data[\"custom_id\"].split(\"-\")[-1]),\n",
    "            # \"test_fold\": df[df[\"id\"] == int(data[\"custom_id\"].split(\"-\")[-1])][\"test_fold\"].values[0]\n",
    "        }\n",
    "        result_df = pd.concat([result_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        i += 1\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f\"few-shot-of-wrong-guesses-dissimilarity-of-fine-tune-fold-{fold}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
